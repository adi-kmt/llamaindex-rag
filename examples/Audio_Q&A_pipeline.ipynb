{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "tr1PnVKC-UxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Qo9qMl9D0p"
      },
      "outputs": [],
      "source": [
        "!pip install pytube transformers rank-bm25\n",
        "!pip install llama-index accelerate optimum bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! CMAKE_ARGS=\"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\" pip install llama-cpp-python"
      ],
      "metadata": {
        "id": "392dNvXaW3or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "w_7SzEuSDjbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "import os\n",
        "from pytube import YouTube\n",
        "from llama_index import SimpleDirectoryReader, PromptHelper\n",
        "from llama_index import VectorStoreIndex, ServiceContext\n",
        "from llama_index.retrievers import BM25Retriever\n",
        "from llama_index.retrievers import QueryFusionRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.prompts import PromptTemplate\n",
        "from transformers import BitsAndBytesConfig\n",
        "from llama_index.llms import HuggingFaceLLM\n",
        "import accelerate"
      ],
      "metadata": {
        "id": "pMSYqbtMCgrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "04rb7jFNI8--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download video from youtube link. Inspired from [link](https://blog.devgenius.io/download-a-video-from-youtube-and-convert-it-to-mp3-using-python-django-552141990d57)\n",
        "Extracted audio and saved it to mp3 file"
      ],
      "metadata": {
        "id": "ZBeyfSqSFwd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "MVN0D1ZNKn8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_save_audio(video_URL, destination, final_filename):\n",
        "  video = YouTube(video_URL)\n",
        "  audio = video.streams.filter(only_audio=True).first()\n",
        "  output = audio.download(output_path = destination)\n",
        "  _, ext = os.path.splitext(output)\n",
        "  new_file = final_filename + '.mp3'\n",
        "  os.rename(output, new_file)"
      ],
      "metadata": {
        "id": "m0HIocyfD8if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Text from mp3 file\n",
        "\n",
        "Using Whisper to extract text using huggingface pipeline"
      ],
      "metadata": {
        "id": "kcmmicIXGgcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_audio(audio_file):\n",
        "  pipe = pipeline(\"automatic-speech-recognition\",\n",
        "                  \"openai/whisper-large-v2\",\n",
        "                  torch_dtype=torch.float16,\n",
        "                  device=\"cuda:0\")\n",
        "\n",
        "  pipe.model = pipe.model.to_bettertransformer()\n",
        "\n",
        "  outputs = pipe(audio_file,\n",
        "                chunk_length_s=30,\n",
        "                batch_size=24,\n",
        "                return_timestamps=True)\n",
        "\n",
        "  with open('data/transcribe.txt', 'w') as f:\n",
        "    f.write(outputs[\"text\"])"
      ],
      "metadata": {
        "id": "zazELO0MEOC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the text file"
      ],
      "metadata": {
        "id": "P3T0sdE0M7mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_and_save_audio(\"https://youtu.be/0eZKYLIrNmQ\", \"/content/\", \"extracted_audio\")"
      ],
      "metadata": {
        "id": "lXuF3DTBNhB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_text_from_audio(\"extracted_audio.mp3\")"
      ],
      "metadata": {
        "id": "KXbkzgqWPmjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "WHzeGGI3LmWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_to_prompt(messages):\n",
        "  prompt = \"\"\n",
        "  for message in messages:\n",
        "    if message.role == 'system':\n",
        "      prompt += f\"<|system|>\\n{message.content}\\n\"\n",
        "    elif message.role == 'user':\n",
        "      prompt += f\"<|user|>\\n{message.content}\\n\"\n",
        "    elif message.role == 'assistant':\n",
        "      prompt += f\"<|assistant|>\\n{message.content}\\n\"\n",
        "\n",
        "  # ensure we start with a system prompt, insert blank if needed\n",
        "  if not prompt.startswith(\"<|system|>\\n\"):\n",
        "    prompt = \"<|system|>\\n\\n\" + prompt\n",
        "\n",
        "  # add final assistant prompt\n",
        "  prompt = prompt + \"<|assistant|>\\n\"\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "8l4KjjBCLn9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a model in 4bit using NF4 quantization with double quantization with the compute dtype bfloat16 for faster training\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "llm_zephyr = HuggingFaceLLM(\n",
        "    model_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    tokenizer_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    query_wrapper_prompt=PromptTemplate(\"<|system|>\\n\\n<|user|>\\n{query_str}\\n<|assistant|>\\n\"),\n",
        "    context_window=10000,\n",
        "    max_new_tokens=10000,\n",
        "    model_kwargs={\"quantization_config\": quantization_config},\n",
        "    # tokenizer_kwargs={},\n",
        "    generate_kwargs={\"temperature\": 0.3, \"top_k\": 50, \"top_p\": 0.95},\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "ocHcpLG0Lq3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLamaindex Hybrid Re-ranking Index"
      ],
      "metadata": {
        "id": "9z-d2uiHIOSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"data/\").load_data()\n",
        "\n",
        "service_context = ServiceContext.from_defaults(chunk_size=256, llm=llm_zephyr)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, service_context=service_context\n",
        ")\n",
        "\n",
        "vector_retriever = index.as_retriever(similarity_top_k=2)"
      ],
      "metadata": {
        "id": "oqNtWM9nIMkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_retriever = BM25Retriever.from_defaults(\n",
        "    docstore=index.docstore, similarity_top_k=2\n",
        ")\n",
        "\n",
        "retriever = QueryFusionRetriever(\n",
        "    [vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=2,\n",
        "    num_queries=4,\n",
        "    mode=\"reciprocal_rerank\",\n",
        "    use_async=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "query_engine = RetrieverQueryEngine.from_args(retriever, service_context=service_context)"
      ],
      "metadata": {
        "id": "cv8bfsn8Wvlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Summarise the Ai head of state?\")"
      ],
      "metadata": {
        "id": "muOzDYBQLBIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsnNY_XHWDoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}